{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating RL MLP for Tic Tac Toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "from IPython.display import display, clear_output\n",
    "from time import sleep\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "from functools import reduce\n",
    "\n",
    "from utils import show_field, Board\n",
    "from agents.random import RandomAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntelligentAgent:\n",
    "    def __init__(self, nn_filename=None, board_dim=3, hidden_size=64):\n",
    "        self.board_dim = board_dim\n",
    "        if nn_filename is None:\n",
    "            self.brain = AgentNN(board_dim, hidden_size)\n",
    "        else:\n",
    "            self.brain = torch.load(nn_filename)\n",
    "\n",
    "        self.optimizer = optim.AdamW(self.brain.parameters(), amsgrad=True)\n",
    "        self.brain.to(device)\n",
    "        self.brain.eval()\n",
    "\n",
    "        self.remap_move = {}\n",
    "        pos = 0\n",
    "        for i in range(board_dim):\n",
    "            for j in range(board_dim):\n",
    "                self.remap_move[pos] = (i, j)\n",
    "                pos += 1\n",
    "\n",
    "    def get_move(self, board):\n",
    "        with torch.no_grad():\n",
    "            thought = self.brain(torch.FloatTensor(board.board.flatten()).to(device))\n",
    "            #print(thought, file=sys.stderr)\n",
    "            return self.remap_move[thought.to('cpu').argmax().item()]\n",
    "\n",
    "    def get_move_batch(self, boards):\n",
    "        thoughts = self.brain(torch.stack([torch.FloatTensor(b[0].board.flatten()) for b in boards]).to(device))\n",
    "        return thoughts\n",
    "\n",
    "    def save(self, file_name):\n",
    "        self.brain.save(file_name)\n",
    "\n",
    "    def train(self, moves, results):\n",
    "        self.brain.train()\n",
    "        actual_moves = self.get_move_batch(moves)\n",
    "        z = torch.zeros(actual_moves.shape[0], 9)\n",
    "        for i, j in zip(range(actual_moves.shape[0]), actual_moves.argmax(dim=1)):\n",
    "            z[i,j] = results[i]\n",
    "        loss = F.cross_entropy(actual_moves, z.to(device))\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "        self.brain.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentNN(nn.Module):\n",
    "    def __init__(self, board_dim=3, hidden_size=64):\n",
    "        super().__init__()\n",
    "        self.board_dim = board_dim\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.input = nn.Linear(board_dim ** 2, hidden_size)\n",
    "        self.hidden = nn.Linear(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, board_dim ** 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.hidden(x)\n",
    "        x = F.relu(x)\n",
    "        return self.out(x)\n",
    "\n",
    "    def save(self, file_name):\n",
    "        torch.save(self, file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def play_single_game(agent_x, agent_o, show=False, win_condition=None):\n",
    "    # Play game and return moves in reversed order\n",
    "\n",
    "    assert agent_x.board_dim == agent_o.board_dim, 'Agents have different dims'\n",
    "    b = Board(agent_x.board_dim, win_condition)\n",
    "    turn = 0\n",
    "    player = [1, -1]\n",
    "    agent = (agent_x, agent_o)\n",
    "    moves = ([], [])\n",
    "    while b.empty_cells > 0:\n",
    "        if show:\n",
    "            b.show()\n",
    "            time.sleep(1)\n",
    "        move = agent[turn].get_move(b)\n",
    "        moves[turn].insert(0, (b.deepcopy(), move))\n",
    "        result = b.make_move(move, player[turn])\n",
    "        if result != 0:\n",
    "            if show:\n",
    "                b.show()\n",
    "                remap = {1: 'x', -1: 'o'}\n",
    "                print(f\"Player '{remap[int(result)]}' wins!\")\n",
    "                time.sleep(1)\n",
    "            return result, moves\n",
    "        turn += 1\n",
    "        turn %= 2\n",
    "    if show:\n",
    "        b.show()\n",
    "        print(f'Draw!')\n",
    "        time.sleep(1)\n",
    "    return 0, moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   \n",
      "    -   -   -   \n",
      "0 | x | x | x |\n",
      "    -   -   -   \n",
      "1 |   | o |   |\n",
      "    -   -   -   \n",
      "2 | o |   |   |\n",
      "    -   -   -   \n",
      "Player 'x' wins!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " ([(<utils.Board at 0x7f86620bae50>, (0, 1)),\n",
       "   (<utils.Board at 0x7f87084e5610>, (0, 0)),\n",
       "   (<utils.Board at 0x7f86e44e5490>, (0, 2))],\n",
       "  [(<utils.Board at 0x7f87085d2c90>, (2, 0)),\n",
       "   (<utils.Board at 0x7f86625e1b10>, (1, 1))]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_o = RandomAgent(3)\n",
    "agent_x = IntelligentAgent('data/test_nn_9')\n",
    "play_single_game(agent_x, agent_o, True, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1.381072675999917, Win rate 0.0 Draw rate 0.0 Win or draw rate 0.0\n",
      "Total time: 2.8823781369999324, Win rate 0.109 Draw rate 0.0 Win or draw rate 0.109\n",
      "Total time: 4.436343383000008, Win rate 0.091 Draw rate 0.0 Win or draw rate 0.091\n",
      "Total time: 6.063992369999937, Win rate 0.078 Draw rate 0.0 Win or draw rate 0.078\n",
      "Total time: 7.569201131, Win rate 0.435 Draw rate 0.0 Win or draw rate 0.435\n",
      "Total time: 9.279927431999909, Win rate 0.584 Draw rate 0.0 Win or draw rate 0.584\n",
      "Total time: 10.849007207999989, Win rate 0.624 Draw rate 0.0 Win or draw rate 0.624\n",
      "Total time: 12.483505585999978, Win rate 0.621 Draw rate 0.0 Win or draw rate 0.621\n",
      "Total time: 14.125079701000004, Win rate 0.655 Draw rate 0.0 Win or draw rate 0.655\n",
      "Total time: 15.754408292999983, Win rate 0.813 Draw rate 0.0 Win or draw rate 0.813\n"
     ]
    }
   ],
   "source": [
    "START = 0\n",
    "NUM_EPOCHS = 10\n",
    "NUM_GAMES = 1000\n",
    "BATCH_SIZE = 100\n",
    "PRINT_TIME = False\n",
    "    \n",
    "\n",
    "start_time = time.perf_counter()\n",
    "for epoch in range(START, START + NUM_EPOCHS):\n",
    "    file_name = None\n",
    "    if epoch > 0:\n",
    "        file_name = f'data/test_nn_{epoch - 1}'\n",
    "    agent = IntelligentAgent(nn_filename=file_name, hidden_size=2048)\n",
    "    random_agent = RandomAgent(3)\n",
    "    \n",
    "    wins = 0\n",
    "    draws = 0\n",
    "    total_moves = []\n",
    "    results = []\n",
    "    start_batch_time = time.perf_counter()\n",
    "    for i in range(NUM_GAMES):\n",
    "        res, moves = play_single_game(agent, random_agent)\n",
    "        if res == 1:\n",
    "            wins += 1\n",
    "        if res == 0:\n",
    "            draws += 1\n",
    "\n",
    "        # custom loss for draw\n",
    "        if res == 0:\n",
    "            res = 0.9\n",
    "\n",
    "        total_moves += moves[0]\n",
    "        results += [res] * len(moves[0])\n",
    "        \n",
    "        if len(total_moves) >= BATCH_SIZE:\n",
    "            if PRINT_TIME:\n",
    "                print(f'Total time: {time.perf_counter() - start_time}, Time for creating current batch: {time.perf_counter() - start_batch_time}')\n",
    "                start_train_time = time.perf_counter()\n",
    "\n",
    "            agent.train(total_moves, results)\n",
    "\n",
    "            if PRINT_TIME:\n",
    "                print(f'Total time: {time.perf_counter() - start_time}, Time for training current batch: {time.perf_counter() - start_train_time}')\n",
    "\n",
    "\n",
    "            # clear tmp variables\n",
    "            total_moves = []\n",
    "            results = []\n",
    "\n",
    "            if PRINT_TIME:\n",
    "                start_batch_time = time.perf_counter()\n",
    "\n",
    "    if len(total_moves) > 0:\n",
    "        agent.train(total_moves, results)\n",
    "\n",
    "\n",
    "    print(f'Total time: {time.perf_counter() - start_time}, Win rate {wins / NUM_GAMES} Draw rate {draws / NUM_GAMES} Win or draw rate {(draws + wins) / NUM_GAMES}')\n",
    "    agent.save(f'data/test_nn_{epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win rate 0.0\n"
     ]
    }
   ],
   "source": [
    "agent_o = RandomAgent(3)\n",
    "agent_x = IntelligentAgent(nn_filename='test_nn_9')\n",
    "wins = 0\n",
    "games = 1000\n",
    "for i in range(games):\n",
    "    res, _ = play_single_game(agent_x, agent_o)\n",
    "    if res == 1:\n",
    "        wins += 1\n",
    "print(f'Win rate {wins / games}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   \n",
      "    -   -   -   \n",
      "0 |   |   | x |\n",
      "    -   -   -   \n",
      "1 | o | x | o |\n",
      "    -   -   -   \n",
      "2 | x |   |   |\n",
      "    -   -   -   \n",
      "Player 'x' wins!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " ([(<__main__.Board at 0x177ce43d0>, (1, 1)),\n",
       "   (<__main__.Board at 0x293947a90>, (0, 2)),\n",
       "   (<__main__.Board at 0x293946e00>, (2, 0))],\n",
       "  [(<__main__.Board at 0x177ce6290>, (1, 0)),\n",
       "   (<__main__.Board at 0x177ce40d0>, (1, 2))]))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agent_o = IntelligentAgent(nn_filename='test_nn_9')\n",
    "agent_x = IntelligentAgent(nn_filename='test_nn_73')\n",
    "agent_o = RandomAgent(3)\n",
    "# agent_x = RandomAgent(3)\n",
    "play_single_game(agent_x, agent_o, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our NN should return board size output with probabilities of best move\n",
    "# We need to collect all steps of our agent\n",
    "# How do we backprop with this information?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
