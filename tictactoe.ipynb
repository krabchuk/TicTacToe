{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating RL MLP for Tic Tac Toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "from IPython.display import display, clear_output\n",
    "from time import sleep\n",
    "\n",
    "from utils import show_field\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Board:\n",
    "    def __init__(self, board_dim=3, win_condition=None):\n",
    "        self.board_dim = board_dim\n",
    "        if win_condition is None:\n",
    "            self.win_condition = board_dim\n",
    "        else:\n",
    "            self.win_condition = win_condition\n",
    "        # 0: empty\n",
    "        # 1: cross\n",
    "        # -1: nought\n",
    "        self.board = np.zeros((board_dim, board_dim))\n",
    "        self.empty_cells = board_dim * board_dim\n",
    "\n",
    "    def deepcopy(self):\n",
    "        b = Board()\n",
    "        b.board_dim = self.board_dim\n",
    "        b.win_condition = self.win_condition\n",
    "        b.empty_cells = self.empty_cells\n",
    "        b.board = np.copy(self.board)\n",
    "        return b\n",
    "\n",
    "    def check_win(self, i, j):\n",
    "        # vertical\n",
    "        same_cell = 0\n",
    "        k = i + 1\n",
    "        while k < self.board_dim and self.board[k][j] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k += 1\n",
    "\n",
    "        k = i - 1\n",
    "        while k >= 0 and self.board[k][j] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k -= 1\n",
    "\n",
    "        if same_cell == (self.win_condition - 1):\n",
    "            return self.board[i][j]\n",
    "\n",
    "\n",
    "        # horizontals\n",
    "        same_cell = 0\n",
    "        k = j + 1\n",
    "        while k < self.board_dim and self.board[i][k] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k += 1\n",
    "\n",
    "        k = j - 1\n",
    "        while k >= 0 and self.board[i][k] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k -= 1\n",
    "\n",
    "        if same_cell == (self.win_condition - 1):\n",
    "            return self.board[i][j]\n",
    "\n",
    "        # diagonals\n",
    "        same_cell = 0\n",
    "        k = i + 1\n",
    "        l = j + 1\n",
    "        while k < self.board_dim and l < self.board_dim and self.board[k][l] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k += 1\n",
    "            l += 1\n",
    "\n",
    "        k = i - 1\n",
    "        l = j - 1\n",
    "        while k >= 0 and l >= 0 and self.board[k][l] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k -= 1\n",
    "            l -= 1\n",
    "\n",
    "        if same_cell == (self.win_condition - 1):\n",
    "            return self.board[i][j]\n",
    "\n",
    "        same_cell = 0\n",
    "        k = i + 1\n",
    "        l = j - 1\n",
    "        while k < self.board_dim and l >= 0 and self.board[k][l] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k += 1\n",
    "            l -= 1\n",
    "\n",
    "        k = i - 1\n",
    "        l = j + 1\n",
    "        while k >= 0 and l < self.board_dim and self.board[k][l] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k -= 1\n",
    "            l += 1\n",
    "\n",
    "        if same_cell == (self.win_condition - 1):\n",
    "            return self.board[i][j]\n",
    "\n",
    "        return 0\n",
    "\n",
    "    def show(self):\n",
    "        show_field(self.board)\n",
    "\n",
    "    def make_move(self, move, player) -> int:\n",
    "        i = move[0]\n",
    "        j = move[1]\n",
    "        if player not in [1, -1]:\n",
    "            raise ValueError(f\"Illegal player {player}\")\n",
    "\n",
    "\n",
    "        if self.board[i][j] != 0:\n",
    "            return player * -1 # illegal move\n",
    "\n",
    "        self.board[i][j] = player\n",
    "        self.empty_cells -= 1\n",
    "\n",
    "        win = self.check_win(i, j)\n",
    "        if win != 0:\n",
    "            self.empty_cells = 0\n",
    "\n",
    "        return win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    def __init__(self, board_dim):\n",
    "        self.board_dim = board_dim\n",
    "\n",
    "    @staticmethod\n",
    "    def get_move(board):\n",
    "        available_cells = []\n",
    "        for i in range(board.board_dim):\n",
    "            for j in range(board.board_dim):\n",
    "                if board.board[i][j] == 0:\n",
    "                    available_cells.append((i,j))\n",
    "        return available_cells[random.randint(0, len(available_cells) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntelligentAgent:\n",
    "    def __init__(self, nn_filename=None, board_dim=3, hidden_size=64):\n",
    "        self.board_dim = board_dim\n",
    "        if nn_filename is None:\n",
    "            self.brain = AgentNN(board_dim, hidden_size)\n",
    "        else:\n",
    "            self.brain = torch.load(nn_filename)\n",
    "\n",
    "        self.optimizer = optim.AdamW(self.brain.parameters(), amsgrad=True)\n",
    "        self.brain.to(device)\n",
    "        self.brain.eval()\n",
    "\n",
    "        self.remap_move = {}\n",
    "        pos = 0\n",
    "        for i in range(board_dim):\n",
    "            for j in range(board_dim):\n",
    "                self.remap_move[pos] = (i, j)\n",
    "                pos += 1\n",
    "\n",
    "    def get_move(self, board):\n",
    "        with torch.no_grad():\n",
    "            thought = self.brain(torch.FloatTensor(board.board.flatten()).to(device))\n",
    "            #print(thought, file=sys.stderr)\n",
    "            return self.remap_move[thought.to('cpu').argmax().item()]\n",
    "\n",
    "    def get_move_batch(self, boards):\n",
    "        thoughts = self.brain(torch.stack([torch.FloatTensor(b[0].board.flatten()) for b in boards]).to(device))\n",
    "        return thoughts\n",
    "\n",
    "    def save(self, file_name):\n",
    "        self.brain.save(file_name)\n",
    "\n",
    "    def train(self, moves, results):\n",
    "        self.brain.train()\n",
    "        actual_moves = self.get_move_batch(moves)\n",
    "        z = torch.zeros(actual_moves.shape[0], 9)\n",
    "        for i, j in zip(range(actual_moves.shape[0]), actual_moves.argmax(dim=1)):\n",
    "            z[i,j] = results[i]\n",
    "        loss = F.cross_entropy(actual_moves, z.to(device))\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "        self.brain.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentNN(nn.Module):\n",
    "    def __init__(self, board_dim=3, hidden_size=64):\n",
    "        super().__init__()\n",
    "        self.board_dim = board_dim\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.input = nn.Linear(board_dim ** 2, hidden_size)\n",
    "        self.hidden = nn.Linear(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, board_dim ** 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.hidden(x)\n",
    "        x = F.relu(x)\n",
    "        return self.out(x)\n",
    "\n",
    "    def save(self, file_name):\n",
    "        torch.save(self, file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def play_single_game(agent_x, agent_o, show=False, win_condition=None):\n",
    "    # Play game and return moves in reversed order\n",
    "\n",
    "    assert agent_x.board_dim == agent_o.board_dim, 'Agents have different dims'\n",
    "    b = Board(agent_x.board_dim, win_condition)\n",
    "    turn = 0\n",
    "    player = [1, -1]\n",
    "    agent = (agent_x, agent_o)\n",
    "    moves = ([], [])\n",
    "    while b.empty_cells > 0:\n",
    "        if show:\n",
    "            b.show()\n",
    "            time.sleep(1)\n",
    "        move = agent[turn].get_move(b)\n",
    "        moves[turn].insert(0, (b.deepcopy(), move))\n",
    "        result = b.make_move(move, player[turn])\n",
    "        if result != 0:\n",
    "            if show:\n",
    "                b.show()\n",
    "                remap = {1: 'x', -1: 'o'}\n",
    "                print(f\"Player '{remap[int(result)]}' wins!\")\n",
    "                time.sleep(1)\n",
    "            return result, moves\n",
    "        turn += 1\n",
    "        turn %= 2\n",
    "    if show:\n",
    "        b.show()\n",
    "        print(f'Draw!')\n",
    "        time.sleep(1)\n",
    "    return 0, moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   \n",
      "    -   -   -   \n",
      "0 |   |   |   |\n",
      "    -   -   -   \n",
      "1 |   |   |   |\n",
      "    -   -   -   \n",
      "2 | x | o |   |\n",
      "    -   -   -   \n",
      "Player 'o' wins!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1,\n",
       " ([(<__main__.Board at 0x7f08d4c734d0>, (2, 0)),\n",
       "   (<__main__.Board at 0x7f097f180f10>, (2, 0))],\n",
       "  [(<__main__.Board at 0x7f08d516cc90>, (2, 1))]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_o = RandomAgent(3)\n",
    "agent_x = IntelligentAgent('data/test_nn_0')\n",
    "play_single_game(agent_x, agent_o, True, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.zeros(actual_moves.shape[0], 9)\n",
    "for i, j in zip(range(actual_moves.shape[0]), actual_moves.argmax(dim=1)):\n",
    "    z[i,j] = res\n",
    "z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = [[1, 2, 3], [4, 5], [6]]\n",
    "sum(tmp, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 151.6947169969999, Win rate 0.96598 Draw rate 0.00643 Win or draw rate 0.97241\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/krabchuk/TicTacToe/tictactoe.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B51.250.29.187/home/krabchuk/TicTacToe/tictactoe.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m start_batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B51.250.29.187/home/krabchuk/TicTacToe/tictactoe.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(NUM_GAMES):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B51.250.29.187/home/krabchuk/TicTacToe/tictactoe.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     res, moves \u001b[39m=\u001b[39m play_single_game(agent, random_agent)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B51.250.29.187/home/krabchuk/TicTacToe/tictactoe.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B51.250.29.187/home/krabchuk/TicTacToe/tictactoe.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m         wins \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;32m/home/krabchuk/TicTacToe/tictactoe.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B51.250.29.187/home/krabchuk/TicTacToe/tictactoe.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     b\u001b[39m.\u001b[39mshow()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B51.250.29.187/home/krabchuk/TicTacToe/tictactoe.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B51.250.29.187/home/krabchuk/TicTacToe/tictactoe.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m move \u001b[39m=\u001b[39m agent[turn]\u001b[39m.\u001b[39mget_move(b)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B51.250.29.187/home/krabchuk/TicTacToe/tictactoe.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m moves[turn]\u001b[39m.\u001b[39minsert(\u001b[39m0\u001b[39m, (b\u001b[39m.\u001b[39mdeepcopy(), move))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B51.250.29.187/home/krabchuk/TicTacToe/tictactoe.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m result \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mmake_move(move, player[turn])\n",
      "\u001b[1;32m/home/krabchuk/TicTacToe/tictactoe.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B51.250.29.187/home/krabchuk/TicTacToe/tictactoe.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m thought \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbrain(torch\u001b[39m.\u001b[39mFloatTensor(board\u001b[39m.\u001b[39mboard\u001b[39m.\u001b[39mflatten())\u001b[39m.\u001b[39mto(device))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B51.250.29.187/home/krabchuk/TicTacToe/tictactoe.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m#print(thought, file=sys.stderr)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B51.250.29.187/home/krabchuk/TicTacToe/tictactoe.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremap_move[thought\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39margmax()\u001b[39m.\u001b[39mitem()]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "START = 4\n",
    "NUM_EPOCHS = 10\n",
    "NUM_GAMES = 100000\n",
    "BATCH_SIZE = 10000\n",
    "PRINT_TIME = False\n",
    "    \n",
    "\n",
    "start_time = time.perf_counter()\n",
    "for epoch in range(START, START + NUM_EPOCHS):\n",
    "    file_name = None\n",
    "    if epoch > 0:\n",
    "        file_name = f'data/test_nn_{epoch - 1}'\n",
    "    agent = IntelligentAgent(nn_filename=file_name, hidden_size=2048)\n",
    "    random_agent = RandomAgent(3)\n",
    "    \n",
    "    wins = 0\n",
    "    draws = 0\n",
    "    total_moves = []\n",
    "    results = []\n",
    "    start_batch_time = time.perf_counter()\n",
    "    for i in range(NUM_GAMES):\n",
    "        res, moves = play_single_game(agent, random_agent)\n",
    "        if res == 1:\n",
    "            wins += 1\n",
    "        if res == 0:\n",
    "            draws += 1\n",
    "\n",
    "        # custom loss for draw\n",
    "        if res == 0:\n",
    "            res = 0.9\n",
    "\n",
    "        total_moves += moves[0]\n",
    "        results += [res] * len(moves[0])\n",
    "        \n",
    "        if len(total_moves) >= BATCH_SIZE:\n",
    "            if PRINT_TIME:\n",
    "                print(f'Total time: {time.perf_counter() - start_time}, Time for creating current batch: {time.perf_counter() - start_batch_time}')\n",
    "                start_train_time = time.perf_counter()\n",
    "\n",
    "            agent.train(total_moves, results)\n",
    "\n",
    "            if PRINT_TIME:\n",
    "                print(f'Total time: {time.perf_counter() - start_time}, Time for training current batch: {time.perf_counter() - start_train_time}')\n",
    "\n",
    "\n",
    "            # clear tmp variables\n",
    "            total_moves = []\n",
    "            results = []\n",
    "\n",
    "            if PRINT_TIME:\n",
    "                start_batch_time = time.perf_counter()\n",
    "\n",
    "    print(f'Total time: {time.perf_counter() - start_time}, Win rate {wins / NUM_GAMES} Draw rate {draws / NUM_GAMES} Win or draw rate {(draws + wins) / NUM_GAMES}')\n",
    "    agent.save(f'data/test_nn_{epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win rate 0.0\n"
     ]
    }
   ],
   "source": [
    "agent_o = RandomAgent(3)\n",
    "agent_x = IntelligentAgent(nn_filename='test_nn_9')\n",
    "wins = 0\n",
    "games = 1000\n",
    "for i in range(games):\n",
    "    res, _ = play_single_game(agent_x, agent_o)\n",
    "    if res == 1:\n",
    "        wins += 1\n",
    "print(f'Win rate {wins / games}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   \n",
      "    -   -   -   \n",
      "0 |   |   | x |\n",
      "    -   -   -   \n",
      "1 | o | x | o |\n",
      "    -   -   -   \n",
      "2 | x |   |   |\n",
      "    -   -   -   \n",
      "Player 'x' wins!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " ([(<__main__.Board at 0x177ce43d0>, (1, 1)),\n",
       "   (<__main__.Board at 0x293947a90>, (0, 2)),\n",
       "   (<__main__.Board at 0x293946e00>, (2, 0))],\n",
       "  [(<__main__.Board at 0x177ce6290>, (1, 0)),\n",
       "   (<__main__.Board at 0x177ce40d0>, (1, 2))]))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agent_o = IntelligentAgent(nn_filename='test_nn_9')\n",
    "agent_x = IntelligentAgent(nn_filename='test_nn_73')\n",
    "agent_o = RandomAgent(3)\n",
    "# agent_x = RandomAgent(3)\n",
    "play_single_game(agent_x, agent_o, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our NN should return board size output with probabilities of best move\n",
    "# We need to collect all steps of our agent\n",
    "# How do we backprop with this information?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
