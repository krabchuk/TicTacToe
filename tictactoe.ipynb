{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating RL MLP for Tic Tac Toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "from IPython.display import display, clear_output\n",
    "from time import sleep\n",
    "\n",
    "from utils import show_field\n",
    "import numpy as np\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Board:\n",
    "    def __init__(self, board_dim=3, win_condition=None):\n",
    "        self.board_dim = board_dim\n",
    "        if win_condition is None:\n",
    "            self.win_condition = board_dim\n",
    "        else:\n",
    "            self.win_condition = win_condition\n",
    "        # 0: empty\n",
    "        # 1: cross\n",
    "        # -1: nought\n",
    "        self.board = np.zeros((board_dim, board_dim))\n",
    "        self.empty_cells = board_dim * board_dim\n",
    "\n",
    "    def deepcopy(self):\n",
    "        b = Board()\n",
    "        b.board_dim = self.board_dim\n",
    "        b.win_condition = self.win_condition\n",
    "        b.empty_cells = self.empty_cells\n",
    "        b.board = np.copy(self.board)\n",
    "        return b\n",
    "\n",
    "    def check_win(self, i, j):\n",
    "        # vertical\n",
    "        same_cell = 0\n",
    "        k = i + 1\n",
    "        while k < self.board_dim and self.board[k][j] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k += 1\n",
    "\n",
    "        k = i - 1\n",
    "        while k >= 0 and self.board[k][j] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k -= 1\n",
    "\n",
    "        if same_cell == (self.win_condition - 1):\n",
    "            return self.board[i][j]\n",
    "\n",
    "\n",
    "        # horizontals\n",
    "        same_cell = 0\n",
    "        k = j + 1\n",
    "        while k < self.board_dim and self.board[i][k] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k += 1\n",
    "\n",
    "        k = j - 1\n",
    "        while k >= 0 and self.board[i][k] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k -= 1\n",
    "\n",
    "        if same_cell == (self.win_condition - 1):\n",
    "            return self.board[i][j]\n",
    "\n",
    "        # diagonals\n",
    "        same_cell = 0\n",
    "        k = i + 1\n",
    "        l = j + 1\n",
    "        while k < self.board_dim and l < self.board_dim and self.board[k][l] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k += 1\n",
    "            l += 1\n",
    "\n",
    "        k = i - 1\n",
    "        l = j - 1\n",
    "        while k >= 0 and l >= 0 and self.board[k][l] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k -= 1\n",
    "            l -= 1\n",
    "\n",
    "        if same_cell == (self.win_condition - 1):\n",
    "            return self.board[i][j]\n",
    "\n",
    "        same_cell = 0\n",
    "        k = i + 1\n",
    "        l = j - 1\n",
    "        while k < self.board_dim and l >= 0 and self.board[k][l] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k += 1\n",
    "            l -= 1\n",
    "\n",
    "        k = i - 1\n",
    "        l = j + 1\n",
    "        while k >= 0 and l < self.board_dim and self.board[k][l] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k -= 1\n",
    "            l += 1\n",
    "\n",
    "        if same_cell == (self.win_condition - 1):\n",
    "            return self.board[i][j]\n",
    "\n",
    "        return 0\n",
    "\n",
    "    def show(self):\n",
    "        show_field(self.board)\n",
    "\n",
    "    def make_move(self, move, player) -> int:\n",
    "        i = move[0]\n",
    "        j = move[1]\n",
    "        if player not in [1, -1]:\n",
    "            raise ValueError(f\"Illegal player {player}\")\n",
    "\n",
    "\n",
    "        if self.board[i][j] != 0:\n",
    "            return player * -1 # illegal move\n",
    "\n",
    "        self.board[i][j] = player\n",
    "        self.empty_cells -= 1\n",
    "\n",
    "        win = self.check_win(i, j)\n",
    "        if win != 0:\n",
    "            self.empty_cells = 0\n",
    "\n",
    "        return win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    def __init__(self, board_dim):\n",
    "        self.board_dim = board_dim\n",
    "\n",
    "    @staticmethod\n",
    "    def get_move(board):\n",
    "        available_cells = []\n",
    "        for i in range(board.board_dim):\n",
    "            for j in range(board.board_dim):\n",
    "                if board.board[i][j] == 0:\n",
    "                    available_cells.append((i,j))\n",
    "        return available_cells[random.randint(0, len(available_cells) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntelligentAgent:\n",
    "    def __init__(self, nn_filename=None, board_dim=3, hidden_size=64):\n",
    "        self.board_dim = board_dim\n",
    "        if nn_filename is None:\n",
    "            self.brain = AgentNN(board_dim, hidden_size)\n",
    "        else:\n",
    "            self.brain = torch.load(nn_filename)\n",
    "\n",
    "        self.brain.to(device)\n",
    "\n",
    "        self.remap_move = {}\n",
    "        pos = 0\n",
    "        for i in range(board_dim):\n",
    "            for j in range(board_dim):\n",
    "                self.remap_move[pos] = (i, j)\n",
    "                pos += 1\n",
    "\n",
    "    def get_move(self, board):\n",
    "        with torch.no_grad():\n",
    "            thought = self.brain(torch.FloatTensor(board.board.flatten()).to(device))\n",
    "            #print(thought, file=sys.stderr)\n",
    "            return self.remap_move[thought.to('cpu').argmax().item()]\n",
    "\n",
    "    def get_move_batch(self, boards):\n",
    "        thoughts = self.brain(torch.stack([torch.FloatTensor(b[0].board.flatten()) for b in boards]).to(device))\n",
    "        return thoughts\n",
    "\n",
    "    def save(self, file_name):\n",
    "        self.brain.save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentNN(nn.Module):\n",
    "    def __init__(self, board_dim=3, hidden_size=64):\n",
    "        super().__init__()\n",
    "        self.board_dim = board_dim\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.input = nn.Linear(board_dim ** 2, hidden_size)\n",
    "        self.hidden = nn.Linear(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, board_dim ** 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.hidden(x)\n",
    "        x = F.relu(x)\n",
    "        return self.out(x)\n",
    "\n",
    "    def save(self, file_name):\n",
    "        torch.save(self, file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def play_single_game(agent_x, agent_o, show=False, win_condition=None):\n",
    "    # Play game and return moves in reversed order\n",
    "\n",
    "    assert agent_x.board_dim == agent_o.board_dim, 'Agents have different dims'\n",
    "    b = Board(agent_x.board_dim, win_condition)\n",
    "    turn = 0\n",
    "    player = [1, -1]\n",
    "    agent = (agent_x, agent_o)\n",
    "    moves = ([], [])\n",
    "    while b.empty_cells > 0:\n",
    "        if show:\n",
    "            b.show()\n",
    "            time.sleep(1)\n",
    "        move = agent[turn].get_move(b)\n",
    "        moves[turn].insert(0, (b.deepcopy(), move))\n",
    "        result = b.make_move(move, player[turn])\n",
    "        if result != 0:\n",
    "            if show:\n",
    "                b.show()\n",
    "                remap = {1: 'x', -1: 'o'}\n",
    "                print(f\"Player '{remap[int(result)]}' wins!\")\n",
    "                time.sleep(1)\n",
    "            return result, moves\n",
    "        turn += 1\n",
    "        turn %= 2\n",
    "    if show:\n",
    "        b.show()\n",
    "        print(f'Draw!')\n",
    "        time.sleep(1)\n",
    "    return 0, moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   \n",
      "    -   -   -   \n",
      "0 |   |   |   |\n",
      "    -   -   -   \n",
      "1 |   |   |   |\n",
      "    -   -   -   \n",
      "2 | x | o |   |\n",
      "    -   -   -   \n",
      "Player 'o' wins!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1,\n",
       " ([(<__main__.Board at 0x7f08d4c734d0>, (2, 0)),\n",
       "   (<__main__.Board at 0x7f097f180f10>, (2, 0))],\n",
       "  [(<__main__.Board at 0x7f08d516cc90>, (2, 1))]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_o = RandomAgent(3)\n",
    "agent_x = IntelligentAgent('data/test_nn_0')\n",
    "play_single_game(agent_x, agent_o, True, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.zeros(actual_moves.shape[0], 9)\n",
    "for i, j in zip(range(actual_moves.shape[0]), actual_moves.argmax(dim=1)):\n",
    "    z[i,j] = res\n",
    "z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win rate 0.5914 Draw rate 0.0 Win or draw rate 0.5914\n",
      "Win rate 0.6342 Draw rate 0.0 Win or draw rate 0.6342\n",
      "Win rate 0.6232 Draw rate 0.0 Win or draw rate 0.6232\n",
      "Win rate 0.6244 Draw rate 0.0 Win or draw rate 0.6244\n",
      "Win rate 0.6268 Draw rate 0.0 Win or draw rate 0.6268\n",
      "Win rate 0.6296 Draw rate 0.0 Win or draw rate 0.6296\n",
      "Win rate 0.6254 Draw rate 0.0 Win or draw rate 0.6254\n",
      "Win rate 0.629 Draw rate 0.0 Win or draw rate 0.629\n"
     ]
    }
   ],
   "source": [
    "START = 0\n",
    "NUM_EPOCHS = 10\n",
    "NUM_GAMES = 5000\n",
    "\n",
    "for epoch in range(START, START + NUM_EPOCHS):\n",
    "    file_name = None\n",
    "    if epoch > 0:\n",
    "        file_name = f'data/test_nn_{epoch - 1}'\n",
    "    agent = IntelligentAgent(nn_filename=file_name, hidden_size=256)\n",
    "    random_agent = RandomAgent(3)\n",
    "    \n",
    "    optimizer = optim.AdamW(agent.brain.parameters(), amsgrad=True)\n",
    "    wins = 0\n",
    "    draws = 0\n",
    "    for i in range(NUM_GAMES):\n",
    "        res, moves = play_single_game(agent, random_agent)\n",
    "        if res == 1:\n",
    "            wins += 1\n",
    "        if res == 0:\n",
    "            draws += 1\n",
    "\n",
    "        # custom loss for draw\n",
    "        if res == 0:\n",
    "            res = 1\n",
    "        actual_moves = agent.get_move_batch(moves[0])\n",
    "        z = torch.zeros(actual_moves.shape[0], 9)\n",
    "        for i, j in zip(range(actual_moves.shape[0]), actual_moves.argmax(dim=1)):\n",
    "            z[i,j] = res\n",
    "        loss = F.cross_entropy(actual_moves, z.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(f'Win rate {wins / NUM_GAMES} Draw rate {draws / NUM_GAMES} Win or draw rate {(draws + wins) / NUM_GAMES}')\n",
    "    agent.save(f'data/test_nn_{epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win rate 0.0\n"
     ]
    }
   ],
   "source": [
    "agent_o = RandomAgent(3)\n",
    "agent_x = IntelligentAgent(nn_filename='test_nn_9')\n",
    "wins = 0\n",
    "games = 1000\n",
    "for i in range(games):\n",
    "    res, _ = play_single_game(agent_x, agent_o)\n",
    "    if res == 1:\n",
    "        wins += 1\n",
    "print(f'Win rate {wins / games}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   \n",
      "    -   -   -   \n",
      "0 |   |   | x |\n",
      "    -   -   -   \n",
      "1 | o | x | o |\n",
      "    -   -   -   \n",
      "2 | x |   |   |\n",
      "    -   -   -   \n",
      "Player 'x' wins!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " ([(<__main__.Board at 0x177ce43d0>, (1, 1)),\n",
       "   (<__main__.Board at 0x293947a90>, (0, 2)),\n",
       "   (<__main__.Board at 0x293946e00>, (2, 0))],\n",
       "  [(<__main__.Board at 0x177ce6290>, (1, 0)),\n",
       "   (<__main__.Board at 0x177ce40d0>, (1, 2))]))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agent_o = IntelligentAgent(nn_filename='test_nn_9')\n",
    "agent_x = IntelligentAgent(nn_filename='test_nn_73')\n",
    "agent_o = RandomAgent(3)\n",
    "# agent_x = RandomAgent(3)\n",
    "play_single_game(agent_x, agent_o, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our NN should return board size output with probabilities of best move\n",
    "# We need to collect all steps of our agent\n",
    "# How do we backprop with this information?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
