{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating RL MLP for Tic Tac Toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "from IPython.display import display, clear_output\n",
    "from time import sleep\n",
    "\n",
    "from utils import show_field\n",
    "import numpy as np\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Board:\n",
    "    def __init__(self, board_dim=3, win_condition=None):\n",
    "        self.board_dim = board_dim\n",
    "        if win_condition is None:\n",
    "            self.win_condition = board_dim\n",
    "        else:\n",
    "            self.win_condition = win_condition\n",
    "        # 0: empty\n",
    "        # 1: cross\n",
    "        # -1: nought\n",
    "        self.board = np.zeros((board_dim, board_dim))\n",
    "        self.empty_cells = board_dim * board_dim\n",
    "\n",
    "    def deepcopy(self):\n",
    "        b = Board()\n",
    "        b.board_dim = self.board_dim\n",
    "        b.win_condition = self.win_condition\n",
    "        b.empty_cells = self.empty_cells\n",
    "        b.board = np.copy(self.board)\n",
    "        return b\n",
    "\n",
    "    def check_win(self, i, j):\n",
    "        # vertical\n",
    "        same_cell = 0\n",
    "        k = i + 1\n",
    "        while k < self.board_dim and self.board[k][j] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k += 1\n",
    "\n",
    "        k = i - 1\n",
    "        while k >= 0 and self.board[k][j] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k -= 1\n",
    "\n",
    "        if same_cell == (self.win_condition - 1):\n",
    "            return self.board[i][j]\n",
    "\n",
    "\n",
    "        # horizontals\n",
    "        same_cell = 0\n",
    "        k = j + 1\n",
    "        while k < self.board_dim and self.board[i][k] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k += 1\n",
    "\n",
    "        k = j - 1\n",
    "        while k >= 0 and self.board[i][k] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k -= 1\n",
    "\n",
    "        if same_cell == (self.win_condition - 1):\n",
    "            return self.board[i][j]\n",
    "\n",
    "        # diagonals\n",
    "        same_cell = 0\n",
    "        k = i + 1\n",
    "        l = j + 1\n",
    "        while k < self.board_dim and l < self.board_dim and self.board[k][l] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k += 1\n",
    "            l += 1\n",
    "\n",
    "        k = i - 1\n",
    "        l = j - 1\n",
    "        while k >= 0 and l >= 0 and self.board[k][l] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k -= 1\n",
    "            l -= 1\n",
    "\n",
    "        if same_cell == (self.win_condition - 1):\n",
    "            return self.board[i][j]\n",
    "\n",
    "        same_cell = 0\n",
    "        k = i + 1\n",
    "        l = j - 1\n",
    "        while k < self.board_dim and l >= 0 and self.board[k][l] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k += 1\n",
    "            l -= 1\n",
    "\n",
    "        k = i - 1\n",
    "        l = j + 1\n",
    "        while k >= 0 and l < self.board_dim and self.board[k][l] == self.board[i][j]:\n",
    "            same_cell += 1\n",
    "            k -= 1\n",
    "            l += 1\n",
    "\n",
    "        if same_cell == (self.win_condition - 1):\n",
    "            return self.board[i][j]\n",
    "\n",
    "        return 0\n",
    "\n",
    "    def show(self):\n",
    "        show_field(self.board)\n",
    "\n",
    "    def make_move(self, move, player) -> int:\n",
    "        i = move[0]\n",
    "        j = move[1]\n",
    "        if player not in [1, -1]:\n",
    "            raise ValueError(f\"Illegal player {player}\")\n",
    "\n",
    "\n",
    "        if self.board[i][j] != 0:\n",
    "            return player * -1 # illegal move\n",
    "\n",
    "        self.board[i][j] = player\n",
    "        self.empty_cells -= 1\n",
    "\n",
    "        win = self.check_win(i, j)\n",
    "        if win != 0:\n",
    "            self.empty_cells = 0\n",
    "\n",
    "        return win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    def __init__(self, board_dim):\n",
    "        self.board_dim = board_dim\n",
    "\n",
    "    @staticmethod\n",
    "    def get_move(board):\n",
    "        available_cells = []\n",
    "        for i in range(board.board_dim):\n",
    "            for j in range(board.board_dim):\n",
    "                if board.board[i][j] == 0:\n",
    "                    available_cells.append((i,j))\n",
    "        return available_cells[random.randint(0, len(available_cells) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntelligentAgent:\n",
    "    def __init__(self, nn_filename=None, board_dim=3, hidden_size=64):\n",
    "        self.board_dim = board_dim\n",
    "        if nn_filename is None:\n",
    "            self.brain = AgentNN(board_dim, hidden_size)\n",
    "        else:\n",
    "            self.brain = torch.load(nn_filename)\n",
    "\n",
    "        self.remap_move = {}\n",
    "        pos = 0\n",
    "        for i in range(board_dim):\n",
    "            for j in range(board_dim):\n",
    "                self.remap_move[pos] = (i, j)\n",
    "                pos += 1\n",
    "\n",
    "    def get_move(self, board):\n",
    "        with torch.no_grad():\n",
    "            thought = self.brain(torch.FloatTensor(board.board.flatten()))\n",
    "            #print(thought, file=sys.stderr)\n",
    "            return self.remap_move[thought.argmax().item()]\n",
    "\n",
    "    def get_move_batch(self, boards):\n",
    "        thoughts = self.brain(torch.stack([torch.FloatTensor(b[0].board.flatten()) for b in boards]))\n",
    "        return thoughts\n",
    "\n",
    "    def save(self, file_name):\n",
    "        self.brain.save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentNN(nn.Module):\n",
    "    def __init__(self, board_dim=3, hidden_size=64):\n",
    "        super().__init__()\n",
    "        self.board_dim = board_dim\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.input = nn.Linear(board_dim ** 2, hidden_size)\n",
    "        self.hidden = nn.Linear(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, board_dim ** 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.hidden(x)\n",
    "        x = F.relu(x)\n",
    "        return self.out(x)\n",
    "\n",
    "    def save(self, file_name):\n",
    "        torch.save(self, file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def play_single_game(agent_x, agent_o, show=False, win_condition=None):\n",
    "    # Play game and return moves in reversed order\n",
    "\n",
    "    assert agent_x.board_dim == agent_o.board_dim, 'Agents have different dims'\n",
    "    b = Board(agent_x.board_dim, win_condition)\n",
    "    turn = 0\n",
    "    player = [1, -1]\n",
    "    agent = (agent_x, agent_o)\n",
    "    moves = ([], [])\n",
    "    while b.empty_cells > 0:\n",
    "        if show:\n",
    "            b.show()\n",
    "            time.sleep(1)\n",
    "        move = agent[turn].get_move(b)\n",
    "        moves[turn].insert(0, (b.deepcopy(), move))\n",
    "        result = b.make_move(move, player[turn])\n",
    "        if result != 0:\n",
    "            if show:\n",
    "                b.show()\n",
    "                remap = {1: 'x', -1: 'o'}\n",
    "                print(f\"Player '{remap[int(result)]}' wins!\")\n",
    "                time.sleep(1)\n",
    "            return result, moves\n",
    "        turn += 1\n",
    "        turn %= 2\n",
    "    if show:\n",
    "        b.show()\n",
    "        print(f'Draw!')\n",
    "        time.sleep(1)\n",
    "    return 0, moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   \n",
      "    -   -   -   \n",
      "0 | o | x | x |\n",
      "    -   -   -   \n",
      "1 | x | x | o |\n",
      "    -   -   -   \n",
      "2 | x | o | o |\n",
      "    -   -   -   \n",
      "Player 'x' wins!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " ([(<__main__.Board at 0x126e78850>, (1, 1)),\n",
       "   (<__main__.Board at 0x126e7b550>, (0, 2)),\n",
       "   (<__main__.Board at 0x126e79630>, (2, 0)),\n",
       "   (<__main__.Board at 0x126eea620>, (0, 1)),\n",
       "   (<__main__.Board at 0x126fe23b0>, (1, 0))],\n",
       "  [(<__main__.Board at 0x126e78dc0>, (2, 2)),\n",
       "   (<__main__.Board at 0x126e796c0>, (0, 0)),\n",
       "   (<__main__.Board at 0x126e791e0>, (2, 1)),\n",
       "   (<__main__.Board at 0x126eea6e0>, (1, 2))]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_o = RandomAgent(3)\n",
    "agent_x = RandomAgent(3)\n",
    "play_single_game(agent_o, agent_x, True, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.zeros(actual_moves.shape[0], 9)\n",
    "for i, j in zip(range(actual_moves.shape[0]), actual_moves.argmax(dim=1)):\n",
    "    z[i,j] = res\n",
    "z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win rate 0.94763 Draw rate 0.00428 Win or draw rate 0.95191\n",
      "Win rate 0.95841 Draw rate 0.01257 Win or draw rate 0.97098\n",
      "Win rate 0.96046 Draw rate 0.01514 Win or draw rate 0.9756\n",
      "Win rate 0.95968 Draw rate 0.01398 Win or draw rate 0.97366\n",
      "Win rate 0.95941 Draw rate 0.01534 Win or draw rate 0.97475\n",
      "Win rate 0.9646 Draw rate 0.01401 Win or draw rate 0.97861\n",
      "Win rate 0.96674 Draw rate 0.01578 Win or draw rate 0.98252\n",
      "Win rate 0.96892 Draw rate 0.01305 Win or draw rate 0.98197\n",
      "Win rate 0.97196 Draw rate 0.01458 Win or draw rate 0.98654\n",
      "Win rate 0.95473 Draw rate 0.0131 Win or draw rate 0.96783\n",
      "Win rate 0.96824 Draw rate 0.01518 Win or draw rate 0.98342\n",
      "Win rate 0.96838 Draw rate 0.0149 Win or draw rate 0.98328\n",
      "Win rate 0.96659 Draw rate 0.01413 Win or draw rate 0.98072\n",
      "Win rate 0.96068 Draw rate 0.01358 Win or draw rate 0.97426\n",
      "Win rate 0.96391 Draw rate 0.01576 Win or draw rate 0.97967\n",
      "Win rate 0.9416 Draw rate 0.01369 Win or draw rate 0.95529\n",
      "Win rate 0.95195 Draw rate 0.01443 Win or draw rate 0.96638\n",
      "Win rate 0.95382 Draw rate 0.01306 Win or draw rate 0.96688\n",
      "Win rate 0.9484 Draw rate 0.01319 Win or draw rate 0.96159\n",
      "Win rate 0.96189 Draw rate 0.00632 Win or draw rate 0.96821\n",
      "Win rate 0.9605 Draw rate 0.00674 Win or draw rate 0.96724\n",
      "Win rate 0.95344 Draw rate 0.01257 Win or draw rate 0.96601\n",
      "Win rate 0.94402 Draw rate 0.01522 Win or draw rate 0.95924\n",
      "Win rate 0.94501 Draw rate 0.01457 Win or draw rate 0.95958\n",
      "Win rate 0.93234 Draw rate 0.01199 Win or draw rate 0.94433\n",
      "Win rate 0.94176 Draw rate 0.0134 Win or draw rate 0.95516\n",
      "Win rate 0.9528 Draw rate 0.01427 Win or draw rate 0.96707\n",
      "Win rate 0.95144 Draw rate 0.01434 Win or draw rate 0.96578\n",
      "Win rate 0.94795 Draw rate 0.01574 Win or draw rate 0.96369\n",
      "Win rate 0.95274 Draw rate 0.01346 Win or draw rate 0.9662\n",
      "Win rate 0.95522 Draw rate 0.01548 Win or draw rate 0.9707\n",
      "Win rate 0.95165 Draw rate 0.01381 Win or draw rate 0.96546\n",
      "Win rate 0.95157 Draw rate 0.01436 Win or draw rate 0.96593\n",
      "Win rate 0.95344 Draw rate 0.01503 Win or draw rate 0.96847\n",
      "Win rate 0.93237 Draw rate 0.01532 Win or draw rate 0.94769\n",
      "Win rate 0.95213 Draw rate 0.01578 Win or draw rate 0.96791\n",
      "Win rate 0.9634 Draw rate 0.01674 Win or draw rate 0.98014\n",
      "Win rate 0.96045 Draw rate 0.0111 Win or draw rate 0.97155\n",
      "Win rate 0.96107 Draw rate 0.01145 Win or draw rate 0.97252\n",
      "Win rate 0.94452 Draw rate 0.01219 Win or draw rate 0.95671\n",
      "Win rate 0.94596 Draw rate 0.01196 Win or draw rate 0.95792\n",
      "Win rate 0.91445 Draw rate 0.01302 Win or draw rate 0.92747\n",
      "Win rate 0.81453 Draw rate 0.01906 Win or draw rate 0.83359\n",
      "Win rate 0.90652 Draw rate 0.00379 Win or draw rate 0.91031\n",
      "Win rate 0.94995 Draw rate 0.01195 Win or draw rate 0.9619\n",
      "Win rate 0.94847 Draw rate 0.01556 Win or draw rate 0.96403\n",
      "Win rate 0.9542 Draw rate 0.01458 Win or draw rate 0.96878\n",
      "Win rate 0.95218 Draw rate 0.01542 Win or draw rate 0.9676\n",
      "Win rate 0.95643 Draw rate 0.01515 Win or draw rate 0.97158\n",
      "Win rate 0.95306 Draw rate 0.01351 Win or draw rate 0.96657\n",
      "Win rate 0.95481 Draw rate 0.01447 Win or draw rate 0.96928\n",
      "Win rate 0.95307 Draw rate 0.01453 Win or draw rate 0.9676\n",
      "Win rate 0.95111 Draw rate 0.01467 Win or draw rate 0.96578\n",
      "Win rate 0.92665 Draw rate 0.01251 Win or draw rate 0.93916\n",
      "Win rate 0.92739 Draw rate 0.00992 Win or draw rate 0.93731\n",
      "Win rate 0.96046 Draw rate 0.01228 Win or draw rate 0.97274\n",
      "Win rate 0.96079 Draw rate 0.0118 Win or draw rate 0.97259\n",
      "Win rate 0.93821 Draw rate 0.01078 Win or draw rate 0.94899\n",
      "Win rate 0.95464 Draw rate 0.01545 Win or draw rate 0.97009\n",
      "Win rate 0.94923 Draw rate 0.01212 Win or draw rate 0.96135\n",
      "Win rate 0.9552 Draw rate 0.01509 Win or draw rate 0.97029\n",
      "Win rate 0.9454 Draw rate 0.01426 Win or draw rate 0.95966\n",
      "Win rate 0.95169 Draw rate 0.01373 Win or draw rate 0.96542\n",
      "Win rate 0.95168 Draw rate 0.01532 Win or draw rate 0.967\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/krabchuk/tmp/TicTacToe/tictactoe.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/krabchuk/tmp/TicTacToe/tictactoe.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(actual_moves, z)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/krabchuk/tmp/TicTacToe/tictactoe.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/krabchuk/tmp/TicTacToe/tictactoe.ipynb#X11sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/krabchuk/tmp/TicTacToe/tictactoe.ipynb#X11sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/krabchuk/tmp/TicTacToe/tictactoe.ipynb#X11sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mWin rate \u001b[39m\u001b[39m{\u001b[39;00mwins \u001b[39m/\u001b[39m NUM_GAMES\u001b[39m}\u001b[39;00m\u001b[39m Draw rate \u001b[39m\u001b[39m{\u001b[39;00mdraws \u001b[39m/\u001b[39m NUM_GAMES\u001b[39m}\u001b[39;00m\u001b[39m Win or draw rate \u001b[39m\u001b[39m{\u001b[39;00m(draws \u001b[39m+\u001b[39m wins) \u001b[39m/\u001b[39m NUM_GAMES\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/optim/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/optim/adamw.py:161\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    157\u001b[0m             max_exp_avg_sqs\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmax_exp_avg_sq\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    159\u001b[0m         state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 161\u001b[0m     adamw(params_with_grad,\n\u001b[1;32m    162\u001b[0m           grads,\n\u001b[1;32m    163\u001b[0m           exp_avgs,\n\u001b[1;32m    164\u001b[0m           exp_avg_sqs,\n\u001b[1;32m    165\u001b[0m           max_exp_avg_sqs,\n\u001b[1;32m    166\u001b[0m           state_steps,\n\u001b[1;32m    167\u001b[0m           amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    168\u001b[0m           beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    169\u001b[0m           beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    170\u001b[0m           lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    171\u001b[0m           weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    172\u001b[0m           eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    173\u001b[0m           maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    174\u001b[0m           foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    175\u001b[0m           capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/optim/adamw.py:218\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 218\u001b[0m func(params,\n\u001b[1;32m    219\u001b[0m      grads,\n\u001b[1;32m    220\u001b[0m      exp_avgs,\n\u001b[1;32m    221\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    222\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    223\u001b[0m      state_steps,\n\u001b[1;32m    224\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    225\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    226\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    227\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    228\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    229\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    230\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    231\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/optim/adamw.py:267\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    266\u001b[0m exp_avg\u001b[39m.\u001b[39mmul_(beta1)\u001b[39m.\u001b[39madd_(grad, alpha\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta1)\n\u001b[0;32m--> 267\u001b[0m exp_avg_sq\u001b[39m.\u001b[39;49mmul_(beta2)\u001b[39m.\u001b[39maddcmul_(grad, grad, value\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta2)\n\u001b[1;32m    269\u001b[0m \u001b[39mif\u001b[39;00m capturable:\n\u001b[1;32m    270\u001b[0m     step \u001b[39m=\u001b[39m step_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "START = 10\n",
    "NUM_EPOCHS = 100\n",
    "NUM_GAMES = 100000\n",
    "\n",
    "for epoch in range(START, START + NUM_EPOCHS):\n",
    "    file_name = None\n",
    "    if epoch > 0:\n",
    "        file_name = f'test_nn_{epoch - 1}'\n",
    "    agent = IntelligentAgent(nn_filename=file_name, hidden_size=256)\n",
    "    random_agent = RandomAgent(3)\n",
    "    optimizer = optim.AdamW(agent.brain.parameters(), amsgrad=True)\n",
    "    wins = 0\n",
    "    draws = 0\n",
    "    for i in range(NUM_GAMES):\n",
    "        res, moves = play_single_game(agent, random_agent)\n",
    "        if res == 1:\n",
    "            wins += 1\n",
    "        if res == 0:\n",
    "            draws += 1\n",
    "\n",
    "        # custom loss for draw\n",
    "        if res == 0:\n",
    "            res = 1\n",
    "        actual_moves = agent.get_move_batch(moves[0])\n",
    "        z = torch.zeros(actual_moves.shape[0], 9)\n",
    "        for i, j in zip(range(actual_moves.shape[0]), actual_moves.argmax(dim=1)):\n",
    "            z[i,j] = res\n",
    "        loss = F.cross_entropy(actual_moves, z)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(f'Win rate {wins / NUM_GAMES} Draw rate {draws / NUM_GAMES} Win or draw rate {(draws + wins) / NUM_GAMES}')\n",
    "    agent.save(f'test_nn_{epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win rate 0.0\n"
     ]
    }
   ],
   "source": [
    "agent_o = RandomAgent(3)\n",
    "agent_x = IntelligentAgent(nn_filename='test_nn_9')\n",
    "wins = 0\n",
    "games = 1000\n",
    "for i in range(games):\n",
    "    res, _ = play_single_game(agent_x, agent_o)\n",
    "    if res == 1:\n",
    "        wins += 1\n",
    "print(f'Win rate {wins / games}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   \n",
      "    -   -   -   \n",
      "0 |   |   | x |\n",
      "    -   -   -   \n",
      "1 | o | x | o |\n",
      "    -   -   -   \n",
      "2 | x |   |   |\n",
      "    -   -   -   \n",
      "Player 'x' wins!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " ([(<__main__.Board at 0x177ce43d0>, (1, 1)),\n",
       "   (<__main__.Board at 0x293947a90>, (0, 2)),\n",
       "   (<__main__.Board at 0x293946e00>, (2, 0))],\n",
       "  [(<__main__.Board at 0x177ce6290>, (1, 0)),\n",
       "   (<__main__.Board at 0x177ce40d0>, (1, 2))]))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agent_o = IntelligentAgent(nn_filename='test_nn_9')\n",
    "agent_x = IntelligentAgent(nn_filename='test_nn_73')\n",
    "agent_o = RandomAgent(3)\n",
    "# agent_x = RandomAgent(3)\n",
    "play_single_game(agent_x, agent_o, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our NN should return board size output with probabilities of best move\n",
    "# We need to collect all steps of our agent\n",
    "# How do we backprop with this information?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
